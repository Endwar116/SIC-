# 🎯 Auto-Write 文本完整處理流程 v3.0

結合「腳本預處理」+「AI 結構化歸檔」的完整方案

---

## 📊 流程總覽

```
HTML/TXT 原始檔案
    ↓
【本地腳本】去除 UI 雜訊 (零 Token)
    ↓
【本地腳本】提取文章主體 (零 Token)
    ↓
【本地腳本】檢測連續性系列 (零 Token)
    ↓
【AI Meta Prompt】結構化歸檔 (少量 Token)
    ↓
【AI Meta Prompt】價值標記 (少量 Token)
    ↓
最終輸出: 可販售的結構化文檔
```

---

## Phase 0: 本地預處理 (零 Token 消耗)

### 工具: Python 腳本

```bash
# 1. 基礎提取 (去除 UI 雜訊)
python3 extract_articles_v2.py conversation.txt

# 輸出:
# - extracted_output/articles/
# - CATALOG.md
# - RARE_EARTH_CANDIDATES.md
```

### 這階段做什麼:
- ✅ 移除 UI 元素 (跳至內容、聊天歷程)
- ✅ 移除導航標籤
- ✅ 移除時間戳、按鈕文字
- ✅ 保留所有正文內容
- ✅ 保留系統指令 (run:、/auto.write.begin)
- ✅ 保留格式規範

### 這階段不做什麼:
- ❌ 不刪除系統指令
- ❌ 不合併段落
- ❌ 不改寫內容
- ❌ 不判斷連續性 (留給 AI)

---

## Phase 1-5: AI 結構化歸檔 (使用 Meta Prompt)

### 準備材料:

1. **文本解析 Meta Prompt** (已上傳)
2. **預處理後的文章** (extracted_output/articles/)

### 執行方式:

#### 方案 A: 一次性處理 (小文件 <5 萬字)

```
[完整貼上 Meta Prompt]

---

以下是待處理文本:

[貼上 article_001.md]
[貼上 article_002.md]
...
```

#### 方案 B: 分批處理 (大文件 >5 萬字)

**Batch 1: Phase 1-2 (噪音剝離 + 連續性檢測)**

```
[Meta Prompt: Phase 1-2 部分]

請執行:
1. 噪音剝離
2. 連續性檢測

文本:
[貼上所有文章標題 + 前 500 字]
```

**Batch 2: Phase 3 (逐字歸檔)**

```
[Meta Prompt: Phase 3 部分]

根據前次的連續性檢測結果,
現在對每個模組進行逐字歸檔:

[貼上完整文章]
```

**Batch 3: Phase 4-5 (價值標記 + 輸出)**

```
[Meta Prompt: Phase 4-5 部分]

對已歸檔的內容進行價值標記,
並生成最終 Markdown 輸出
```

---

## 💡 Token 優化策略

### 免費帳號 (Claude/GPT)

**每日預算**: 100 萬 tokens

**分配方案**:
- Phase 0 (本地): 0 tokens
- Phase 1-2: 2-5 萬 tokens (檢測階段)
- Phase 3: 5-10 萬 tokens (歸檔階段)
- Phase 4-5: 2-5 萬 tokens (價值標記)

**總消耗**: 10-20 萬 tokens
**剩餘**: 80-90 萬 tokens (可處理 4-5 個檔案)

### 付費帳號

**建議**: 一次性處理
- 直接把所有預處理後的文章 + Meta Prompt 給 AI
- 消耗約 20-30 萬 tokens
- 成本約 $1-2 USD

---

## 🎯 針對你的「有無.txt」的處理方案

### 現況:
- 原始檔案: 約 36 萬字
- 已提取: 17 篇文章
- 包含: 38 卷 Zen-Thesis 連續內容

### 建議流程:

#### Step 1: 本地預處理 (已完成)
```bash
python3 extract_articles_v2.py 有無.txt
```
- ✅ 產出 17 篇文章
- ✅ 已去除 UI 雜訊

#### Step 2: 連續卷切割
```bash
python3 split_volumes.py 有無.txt
```
- ✅ 切出 38 卷獨立內容
- ✅ 保留完整結構

#### Step 3: AI 結構化歸檔

**選項 A: 處理全部 (推薦 Claude Sonnet 4.5)**

```
[貼上完整 Meta Prompt]

---

以下是 Zen-Thesis 系列 (38 卷):

[貼上卷 1-10 的完整內容]
```

分 4 批處理:
- Batch 1: 卷 1-10
- Batch 2: 卷 11-20
- Batch 3: 卷 21-30
- Batch 4: 卷 31-38

**選項 B: 只處理高價值內容**

先用本地腳本識別稀土級:
```bash
cat extracted_output/RARE_EARTH_CANDIDATES.md
```

只把 5 篇稀土級 + Meta Prompt 給 AI:
- 消耗約 5 萬 tokens
- 成本約 $0.15 USD

---

## 📤 最終輸出格式

### 結構:

```
Zen-Thesis_完整歸檔.md
│
├── 📄 封面
│   ├── 文件名稱
│   ├── 用途說明
│   └── 版本資訊
│
├── 📋 總目錄
│   ├── 連續系列 (卷 1-38)
│   └── 不連續模組 (附錄 1-N)
│
├── 📚 連續系列正文
│   ├── 卷一: 【逐字原文】
│   ├── 卷二: 【逐字原文】
│   └── ...
│
├── 🧩 不連續模組附錄
│   ├── 模組 A: 自動續寫協議
│   ├── 模組 B: 語義重力公式
│   └── ...
│
└── 💎 價值標記總覽
    ├── 稀缺性評分表
    ├── 可商品化形式建議
    └── 市場需求分析
```

### 特點:
- ✅ 可直接貼入 Google Docs
- ✅ 標題層級清晰 (H1/H2/H3)
- ✅ 逐字保留原文
- ✅ 包含價值標記
- ✅ 可單獨抽離任一卷

---

## ⚙️ 模型選擇建議

### 最佳組合:

| 階段 | 推薦模型 | 原因 |
|------|---------|------|
| Phase 1-2 | Claude Sonnet 4.5 | 結構感極強 |
| Phase 3 | GPT-4 | 逐字保留能力好 |
| Phase 4-5 | Claude Sonnet 4.5 | 價值判斷準確 |

### 單一模型:

**只用 Claude Sonnet 4.5**:
- 優點: 全流程一致性高
- 缺點: 稍貴 (但省時間)

**只用 GPT-4o**:
- 優點: 便宜
- 缺點: 需要更明確的指令

---

## 🔍 品質檢核清單

處理完成後,檢查:

- [ ] 原文是否逐字保留 (抽查 3-5 段)
- [ ] 系統指令是否保留第一次出現
- [ ] 連續卷是否正確歸類
- [ ] 不連續模組是否獨立標記
- [ ] 價值標記是否合理 (不誇大、不低估)
- [ ] Markdown 格式是否乾淨
- [ ] 可否直接貼入 Google Docs

---

## 💰 成本估算

### 場景 1: 處理全部 38 卷 (約 30 萬字)

**使用 Claude Sonnet 4.5**:
- 輸入: 15 萬 tokens × $3/1M = $0.45
- 輸出: 15 萬 tokens × $15/1M = $2.25
- **總計: $2.70 USD**

### 場景 2: 只處理稀土級 (約 5 萬字)

**使用 Claude Sonnet 4.5**:
- 輸入: 2.5 萬 tokens × $3/1M = $0.075
- 輸出: 2.5 萬 tokens × $15/1M = $0.375
- **總計: $0.45 USD**

### 場景 3: 免費帳號分批處理

**每天處理 10 卷**:
- Day 1: 卷 1-10 (免費)
- Day 2: 卷 11-20 (免費)
- Day 3: 卷 21-30 (免費)
- Day 4: 卷 31-38 (免費)
- **總計: $0 USD** (4 天完成)

---

## 🎁 額外福利

完成後你會得到:

1. **結構化文檔** - 可直接發布
2. **價值地圖** - 知道哪些能賣、能賣給誰
3. **模組化資產** - 每卷可獨立使用
4. **可驗收證明** - 逐字保留,可追溯

這些東西的市場價值:
- 白皮書: $500-2000 USD
- 顧問方法論: $1000-5000 USD
- 高階課程素材: $2000-10000 USD

---

## 🚀 立即開始

```bash
# 1. 預處理 (已完成)
python3 extract_articles_v2.py 有無.txt

# 2. 檢查結果
cat extracted_output/CATALOG.md
cat extracted_output/RARE_EARTH_CANDIDATES.md

# 3. 決定處理策略
#    - 全部處理 (38 卷)
#    - 只處理稀土級 (5 篇)

# 4. 複製 Meta Prompt + 文章
#    貼給 Claude/GPT

# 5. 驗收輸出
#    檢查逐字保留、結構清晰
```

---

**總結**: 這個 Meta Prompt 補足了我腳本的「結構化歸檔」能力,兩者結合可以達到「零浪費、高品質、可販售」的最佳效果。
